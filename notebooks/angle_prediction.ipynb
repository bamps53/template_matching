{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypng\n",
      "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m964.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypng\n",
      "Successfully installed pypng-0.20220715.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pypng\n",
    "# !pip install tensorflow-datasets==4.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17938/2293679924.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'png'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import png\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "def as_path(path) -> tfds.core.ReadWritePath:\n",
    "  \"\"\"Convert str or pathlike object to tfds.core.ReadWritePath.\n",
    "\n",
    "  Instead of pathlib.Paths, we use the TFDS path because they transparently\n",
    "  support paths to GCS buckets such as \"gs://kubric-public/GSO\".\n",
    "  \"\"\"\n",
    "  return tfds.core.as_path(path)\n",
    "\n",
    "def read_png(filename, rescale_range=None) -> np.ndarray:\n",
    "  filename = as_path(filename)\n",
    "  png_reader = png.Reader(bytes=filename.read_bytes())\n",
    "  width, height, pngdata, info = png_reader.read()\n",
    "  del png_reader\n",
    "\n",
    "  bitdepth = info[\"bitdepth\"]\n",
    "  if bitdepth == 8:\n",
    "    dtype = np.uint8\n",
    "  elif bitdepth == 16:\n",
    "    dtype = np.uint16\n",
    "  else:\n",
    "    raise NotImplementedError(f\"Unsupported bitdepth: {bitdepth}\")\n",
    "\n",
    "  plane_count = info[\"planes\"]\n",
    "  pngdata = np.vstack(list(map(dtype, pngdata)))\n",
    "  if rescale_range is not None:\n",
    "    minv, maxv = rescale_range\n",
    "    pngdata = pngdata / 2**bitdepth * (maxv - minv) + minv\n",
    "\n",
    "  return pngdata.reshape((height, width, plane_count))\n",
    "\n",
    "\n",
    "data_dir = '../my_kubric/output/train/00000000/'\n",
    "img = cv2.imread(f'{data_dir}/rgba_00000.png')\n",
    "segm = read_png(f'{data_dir}/segmentation_00000.png')\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(segm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f43fc606190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_ids = np.unique(segm)\n",
    "\n",
    "plt.imshow((segm==unique_ids[1]).astype(np.uint8) * 255, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def save_json(file_path, data):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "metadata = load_json(f'{data_dir}/metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Instance(BaseModel):\n",
    "    angular_velocities: List[List[float]]\n",
    "    asset_id: str\n",
    "    bbox_frames: List[int]\n",
    "    bboxes: List[List[float]]\n",
    "    bboxes_3d: List[List[List[float]]]\n",
    "    category: str\n",
    "    description: str\n",
    "    friction: float\n",
    "    image_positions: List[List[float]]\n",
    "    mass: float\n",
    "    nr_faces: int\n",
    "    nr_vertices: int\n",
    "    positions: List[List[float]]\n",
    "    quaternions: List[List[float]]\n",
    "    restitution: float\n",
    "    surface_area: float\n",
    "    velocities: List[List[float]]\n",
    "    visibility: List[int]\n",
    "    volume: float\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join(f'{k}: {v}' for k, v in self.dict().items())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join(f'{k}: {v}' for k, v in self.dict().items())\n",
    "    \n",
    "    def get_angle(self):\n",
    "        \"\"\"\n",
    "        Convert quaternion to angle.\n",
    "        Object is rotated around the z-axis, so we only need to consider the z-component of the quaternion.\n",
    "        \"\"\"\n",
    "        # クオータニオンから要素を取り出す\n",
    "        a, _, _, b = self.quaternions[0]\n",
    "\n",
    "        # クオータニオンから角度を取得\n",
    "        angle = 2 * math.atan2(b, a) * -1\n",
    "\n",
    "        # 角度をdegreeに変換\n",
    "        angle = math.degrees(angle)\n",
    "        \n",
    "        return angle\n",
    "\n",
    "        \n",
    "    \n",
    "instances = [Instance(**json_dict) for json_dict in metadata['instances']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angular_velocities: [[0.0, 0.0, 0.0]]\n",
       "asset_id: Ecoforms_Garden_Pot_GP16ATurquois\n",
       "bbox_frames: [0]\n",
       "bboxes: [[0.35625, 0.63359375, 0.47291666666666665, 0.72109375]]\n",
       "bboxes_3d: [[[-6.220331923186172, -0.6878192984869516, -3.5797270481197074e-08], [-6.220331923186172, -0.6878192984869516, 2.3726825682897896], [-3.8173730145992346, -0.4423583191165288, -3.5797270481197074e-08], [-3.8173730145992346, -0.4423583191165288, 2.3726825682897896], [-5.97441584517588, -3.09523342978898, -3.5797270481197074e-08], [-5.97441584517588, -3.09523342978898, 2.3726825682897896], [-3.571456936588943, -2.849772450418557, -3.5797270481197074e-08], [-3.571456936588943, -2.849772450418557, 2.3726825682897896]]]\n",
       "category: None\n",
       "description: Ecoforms Garden Pot, GP16A-Turquois\n",
       "friction: 0.5\n",
       "image_positions: [[0.6693840026855469, 0.4163177013397217]]\n",
       "mass: 0.0001597794837694265\n",
       "nr_faces: 9126\n",
       "nr_vertices: 4863\n",
       "positions: [[-4.872437000274658, -1.8053804636001587, 1.2343705892562866]]\n",
       "quaternions: [[-0.7421659827232361, 0.0, 0.0, 0.6702161431312561]]\n",
       "restitution: 0.5\n",
       "surface_area: 0.15844204715384813\n",
       "velocities: [[0.0, 0.0, 0.0]]\n",
       "visibility: [9509]\n",
       "volume: 0.0001597794837694265"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  58,  67,  76,  86,  94,  95,  97, 100, 104, 107, 111, 112,\n",
       "       116, 130, 133, 145, 146, 148, 151, 152, 155, 159, 162, 164, 169,\n",
       "       173, 182, 187, 191], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'background': 'sunflowers',\n",
       " 'frame_rate': 12,\n",
       " 'gravity': [0.0, 0.0, -10.0],\n",
       " 'num_frames': 1,\n",
       " 'num_instances': 34,\n",
       " 'resolution': [1280, 960],\n",
       " 'seed': 304266624,\n",
       " 'step_rate': 240}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.v2 import build_yolox_backbone\n",
    "from models.yolox_models.darknet import CSPDarknet\n",
    "depth = 0.33\n",
    "width = 0.50\n",
    "model = CSPDarknet(depth, width, out_features=(\"stem\", \"dark2\", \"dark3\", \"dark4\", \"dark5\"))\n",
    "model = model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(1, 3, 640, 640).cuda()\n",
    "with torch.no_grad():\n",
    "    out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 32, 320, 320]),\n",
       " torch.Size([1, 64, 160, 160]),\n",
       " torch.Size([1, 128, 80, 80]),\n",
       " torch.Size([1, 256, 40, 40]),\n",
       " torch.Size([1, 512, 20, 20])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in out.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, validator\n",
    "import torch\n",
    "\n",
    "class Input(BaseModel):\n",
    "    support_image: torch.Tensor\n",
    "    support_annotation: torch.Tensor\n",
    "    query_image: torch.Tensor\n",
    "    query_annotation: torch.Tensor\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @validator('support_image', 'query_image')\n",
    "    def validate_shape(cls, v: torch.Tensor):\n",
    "        if v.ndim != 4 or v.shape[0] != 1 or v.shape[1] != 3:\n",
    "            raise ValueError('Tensor must be of shape (1, 3, H, W)')\n",
    "        return v\n",
    "\n",
    "    @validator('support_annotation', 'query_annotation')\n",
    "    def validate_shape(cls, v: torch.Tensor):\n",
    "        if v.ndim != 3 or v.shape[0] != 1 or v.shape[-1] != 5:\n",
    "            raise ValueError('Tensor must be of shape (1, N, 5)')\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Input\nquery_annotation\n  Tensor must be of shape (1, N, 5) (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_579/2347853074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msupport_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mquery_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mquery_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydantic/main.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Input\nquery_annotation\n  Tensor must be of shape (1, N, 5) (type=value_error)"
     ]
    }
   ],
   "source": [
    "image_input = Input(\n",
    "    support_image=torch.randn(1, 3, 640, 640),\n",
    "    support_annotation=torch.randn(1, 1, 5),\n",
    "    query_image=torch.randn(1, 3, 640, 640),\n",
    "    query_annotation=torch.randn(1, 1, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 216, 5])\n",
      "torch.Size([1, 216])\n"
     ]
    }
   ],
   "source": [
    "B, N, _ = image_input.query_annotation.shape\n",
    "query_labels = torch.zeros((B, N), dtype=torch.long)\n",
    "\n",
    "# augment positive samples\n",
    "all_query_annotations = []\n",
    "all_query_labels = []\n",
    "for dx in [-1, 0, -1]:\n",
    "    for dy in [-1, 0, -1]:\n",
    "        query_annotations = image_input.query_annotation.clone()\n",
    "        query_labels = torch.ones((B, N), dtype=torch.long)\n",
    "        query_annotations[..., 0] += dx\n",
    "        query_annotations[..., 1] += dy\n",
    "        all_query_annotations.append(query_annotations)\n",
    "        all_query_labels.append(query_labels)\n",
    "\n",
    "query_annotations = torch.cat(all_query_annotations, dim=1)\n",
    "query_labels = torch.cat(all_query_labels, dim=1)\n",
    "\n",
    "# generate negative samples\n",
    "all_query_annotations = [query_annotations.clone()]\n",
    "all_query_labels = [query_labels.clone()]\n",
    "for da in range(15, 360, 15):\n",
    "    query_annotations = query_annotations.clone()\n",
    "    query_labels = torch.zeros_like(query_labels)\n",
    "    query_annotations[..., 4] += da\n",
    "    all_query_annotations.append(query_annotations)\n",
    "    all_query_labels.append(query_labels)\n",
    "\n",
    "query_annotations = torch.cat(all_query_annotations, dim=1)\n",
    "query_labels = torch.cat(all_query_labels, dim=1)\n",
    "\n",
    "print(query_annotations.shape)\n",
    "print(query_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'roi_align'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17364/296405129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoIAlignFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msupport_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroi_feature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRoIAlignFeatureExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtemplate_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroi_feature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_annotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'roi_align'"
     ]
    }
   ],
   "source": [
    "from roi_align import RoIAlignFeatureExtractor\n",
    "\n",
    "support_width, support_height = 10, 10\n",
    "roi_feature_extractor = RoIAlignFeatureExtractor(output_size=(support_width, support_height), sampling_ratio=2)\n",
    "template_image = roi_feature_extractor.extract(image_input.support_image, image_input.support_annotation, spatial_scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
